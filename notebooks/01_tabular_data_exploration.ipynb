{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will look at the necessary steps required before any machine learning takes place.\n",
    "* load the data\n",
    "* look at the variables in the dataset, in particular, differentiate\n",
    "  between numerical and categorical variables, which need different\n",
    "  preprocessing in most machine learning workflows\n",
    "* visualize the distribution of the variables to gain some insights into the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "# plotting style\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the adult census dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data from the \"Current Population adult_census\" from 1994 that we\n",
    "downloaded from [OpenML](http://openml.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\n",
    "    \"https://www.openml.org/data/get_csv/1595261/adult-census.csv\")\n",
    "\n",
    "# Or use the local copy:\n",
    "# adult_census = pd.read_csv('../datasets/adult-census.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the OpenML webpage to know more about this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://www.openml.org/d/1590', width=1200, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the variables in the dataset\n",
    "The data are stored in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column named **class** is our target variable (i.e., the variable which\n",
    "we want to predict). The two possible classes are `<= 50K` (low-revenue) and\n",
    "`> 50K` (high-revenue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'class'\n",
    "adult_census[target_column].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: classes are slightly imbalanced. Class imbalance happens often in\n",
    "practice and may need special techniques for machine learning. For example in\n",
    "a medical setting, if we are trying to predict whether patients will develop\n",
    "a rare disease, there will be a lot more healthy patients than ill patients in\n",
    "the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains both numerical and categorical data. Numerical values\n",
    "can take continuous values for example `age`. Categorical values can have a\n",
    "finite number of values, for example `native-country`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'age', 'education-num', 'capital-gain', 'capital-loss',\n",
    "    'hours-per-week']\n",
    "categorical_columns = [\n",
    "    'workclass', 'education', 'marital-status', 'occupation',\n",
    "    'relationship', 'race', 'sex', 'native-country']\n",
    "all_columns = numerical_columns + categorical_columns + [\n",
    "    target_column]\n",
    "\n",
    "adult_census = adult_census[all_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for simplicity, we have ignored the \"fnlwgt\" (final weight) column\n",
    "that was crafted by the creators of the dataset when sampling the dataset to\n",
    "be representative of the full census database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data\n",
    "Before building a machine learning model, it is a good idea to look at the\n",
    "data:\n",
    "* maybe the task you are trying to achieve can be solved without machine\n",
    "  learning\n",
    "* you need to check that the data you need for your task is indeed present in\n",
    "the dataset\n",
    "* inspecting the data is a good way to find peculiarities. These can can\n",
    "  arise during data collection (for example, malfunctioning sensor or missing\n",
    "  values), or from the way the data is processed afterwards (for example capped\n",
    "  values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of individual variables, to get some insights\n",
    "about the data. We can start by plotting histograms, note that this only\n",
    "works for numerical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = adult_census.hist(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already make a few comments about some of the variables:\n",
    "* age: there are not that many points for 'age > 70'. The dataset description\n",
    "does indicate that retired people have been filtered out (`hours-per-week > 0`).\n",
    "* education-num: peak at 10 and 13, hard to tell what it corresponds to\n",
    "without looking much further. We'll do that later in this notebook.\n",
    "* hours per week peaks at 40, this was very likely the standard number of\n",
    "working hours at the time of the data collection\n",
    "* most values of capital-gain and capital-loss are close to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "For categorical variables, we can look at the distribution of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_census['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_census['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas_profiling` is a nice tool for inspecting the data (both numerical and\n",
    "categorical variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "adult_census.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As noted above, `education-num` distribution has two clear peaks around 10\n",
    "and 13. It would be reasonable to expect that `education-num` is the number of\n",
    "years of education. Let's look at the relationship between `education` and\n",
    "`education-num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=adult_census['education'],\n",
    "            columns=adult_census['education-num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that education and education-num gives you the same information.\n",
    "For example, `education-num=2` is equivalent to `education='1st-4th'`. In\n",
    "practice that means we can remove `education-num` without losing information.\n",
    "Note that having redundant (or highly correlated) columns can be a problem\n",
    "for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to inspect the data is to do a pairplot and show how each variable\n",
    "differs according to our target, `class`. Plots along the diagonal show the\n",
    "distribution of individual variables for each `class`. The plots on the\n",
    "off-diagonal can reveal interesting interactions between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_to_plot = 5000\n",
    "columns = ['age', 'education-num', 'hours-per-week']\n",
    "_ = sns.pairplot(data=adult_census[:n_samples_to_plot], vars=columns,\n",
    "                 hue=target_column, plot_kws={'alpha': 0.2},\n",
    "                 height=4, diag_kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.pairplot(data=adult_census[:n_samples_to_plot], x_vars='age',\n",
    "                 y_vars='hours-per-week', hue=target_column,\n",
    "                 markers=['o',\n",
    "                          'v'], plot_kws={'alpha': 0.2}, height=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "By looking at the data you could infer some hand-written rules to predict the\n",
    "class:\n",
    "* if you are young (less than 25 year-old roughly), you are in the `<= 50K` class.\n",
    "* if you are old (more than 70 year-old roughly), you are in the `<= 50K` class.\n",
    "* if you work part-time (less than 40 hours roughly) you are in the `<= 50K` class.\n",
    "\n",
    "These hand-written rules could work reasonably well without the need for any\n",
    "machine learning. Note however that it is not very easy to create rules for\n",
    "the region `40 < hours-per-week < 60` and `30 < age < 70`. We can hope that\n",
    "machine learning can help in this region. Also note that visualization can\n",
    "help creating hand-written rules but is limited to 2 dimensions (maybe 3\n",
    "dimensions), whereas machine learning models can build models in\n",
    "high-dimensional spaces.\n",
    "\n",
    "Another thing worth mentioning in this plot: if you are young (less than 25\n",
    "year-old roughly) or old (more than 70 year-old roughly) you tend to work\n",
    "less. This is a non-linear relationship between age and hours\n",
    "per week. Some machine learning models can only capture linear interactions so\n",
    "this may be a factor when deciding which model to chose.\n",
    "\n",
    "In a machine-learning setting, we will use an algorithm to automatically\n",
    "decide what should be the \"rules\" in order to make predictions on new data.\n",
    "We can check which set of simple rules a decision tree would grasp using the\n",
    "same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree_decision_function(tree, X, y, ax):\n",
    "    \"\"\"Plot the different decision rules found by a `DecisionTreeClassifier`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : DecisionTreeClassifier instance\n",
    "        The decision tree to inspect.\n",
    "    X : dataframe of shape (n_samples, n_features)\n",
    "        The data used to train the `tree` estimator.\n",
    "    y : ndarray of shape (n_samples,)\n",
    "        The target used to train the `tree` estimator.\n",
    "    ax : matplotlib axis\n",
    "        The matplotlib axis where to plot the different decision rules.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy import ndimage\n",
    "\n",
    "    h = 0.02\n",
    "    x_min, x_max = 0, 100\n",
    "    y_min, y_max = 0, 100\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z = tree.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    faces = tree.tree_.apply(\n",
    "        np.c_[xx.ravel(), yy.ravel()].astype(np.float32))\n",
    "    faces = faces.reshape(xx.shape)\n",
    "    border = ndimage.laplace(faces) != 0\n",
    "    ax.scatter(X.iloc[:, 0], X.iloc[:, 1],\n",
    "               c=np.array(['tab:blue',\n",
    "                           'tab:red'])[y], s=60, alpha=0.7)\n",
    "    ax.contourf(xx, yy, Z, alpha=.4, cmap='RdBu_r')\n",
    "    ax.scatter(xx[border], yy[border], marker='.', s=1)\n",
    "    ax.set_xlabel(X.columns[0])\n",
    "    ax.set_ylabel(X.columns[1])\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "    sns.despine(offset=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)  # reset the plotting style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# select a subset of data\n",
    "data_subset = adult_census[:n_samples_to_plot]\n",
    "X = data_subset[[\"age\", \"hours-per-week\"]]\n",
    "y = LabelEncoder().fit_transform(\n",
    "    data_subset[target_column].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a decision tree which we will keep really simple on purpose.\n",
    "We will only allow a maximum of 2 rules to interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "max_leaf_nodes = 3\n",
    "tree = DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes,\n",
    "                              random_state=0)\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the set of rules learnt by the tree then visually check\n",
    "what theses rules look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the tree structure\n",
    "fig, ax = plt.subplots()\n",
    "plot_tree(tree, ax=ax)\n",
    "\n",
    "# plot the decision function learned by the tree\n",
    "fig, ax = plt.subplots()\n",
    "plot_tree_decision_function(tree, X, y, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allowing only 3 leaves in the tree, we get similar rules to the ones we\n",
    "designed by hand:\n",
    "* the persons younger than 28.5 year-old will be considered in the class\n",
    "  earning `<= 50K`.\n",
    "* the persons older than 28.5 and working more than 40.5 hours-per-week\n",
    "  will be considered in the class earning `> 50K`, while the persons working\n",
    "  below 40.5 hours-per-week, will be considered in the class\n",
    "  earning `<= 50K`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "In this notebook we have:\n",
    "* loaded the data from a CSV file using `pandas`\n",
    "* looked at the kind of variables in the dataset, and differentiated\n",
    "  between categorical and numerical variables\n",
    "* inspected the data with `pandas`, `seaborn` and `pandas_profiling`. Data inspection\n",
    "  can allow you to decide whether using machine learning is appropriate for\n",
    "  your data and to highlight potential peculiarities in your data\n",
    "\n",
    "Key ideas discussed:\n",
    "* if your target variable is imbalanced (e.g., you have more samples from one\n",
    "  target category than another), you may need special techniques for machine\n",
    "  learning\n",
    "* having redundant (or highly correlated) columns can be a problem for\n",
    "  machine learning algorithms\n",
    "* some machine learning models can only capture linear interaction so be\n",
    "  aware of non-linear relationships in your data"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "python_scripts//py:percent,notebooks//ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
